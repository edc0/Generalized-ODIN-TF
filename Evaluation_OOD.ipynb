{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sayakpaul/Generalized-ODIN-TF/blob/main/Evaluation_OOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heG-9quwoktf"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rhDWmAR9OERr"
   },
   "outputs": [],
   "source": [
    "# Grab the initial model weights\n",
    "!wget -q https://github.com/sayakpaul/Generalized-ODIN-TF/releases/download/v1.0.0/models.tar.gz\n",
    "!tar xf models.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QDpKFhBfSrR8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Generalized-ODIN-TF' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sayakpaul/Generalized-ODIN-TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wJ4sAReHPETA"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"Generalized-ODIN-TF\")\n",
    "from scripts import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UWypWRHopbU"
   },
   "source": [
    "## Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1laPh_dPKHs",
    "outputId": "9108dfe2-292a-4ed3-837b-223bd8ca2ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained models loaded.\n"
     ]
    }
   ],
   "source": [
    "rn_odin_model = tf.keras.models.load_model(\"odin_rn_model\")\n",
    "rn_baseline_model = tf.keras.models.load_model(\"rn_baseline_model\")\n",
    "print(f\"Pre-trained models loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVV1WGLcorWy"
   },
   "source": [
    "## Load OOD dataset -- SVHN dataset\n",
    "\n",
    "The purpose of this work is to test a model's ability to detect out-of-distribution (OOD) samples. For that purpose, we are using the [SVHN dataset](https://http://ufldl.stanford.edu/housenumbers/) which is an OOD dataset in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "iI_DR5sPPnSN",
    "outputId": "dd3c83d5-84f2-4a67-c716-4467efc5596e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/dolgenercantu/tensorflow_datasets/svhn_cropped/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "ename": "NonMatchingChecksumError",
     "evalue": "Artifact http://ufldl.stanford.edu/housenumbers/extra_32x32.mat, downloaded to /home/dolgenercantu/tensorflow_datasets/downloads/ufldl.stanford.edu_housenumber_extra_32x322H3BskdvSy0nozmNN-lLEutTDhyQSJDShKe3tccJQqI.mat.tmp.0199864c86d74b5d9e8e0157df6fe89b/extra_32x32.mat, has wrong checksum. Expected: UrlInfo(size=1.24 GiB, checksum='a133a4beb38a00fcdda90c9489e0c04f900b660ce8a316a5e854838379a71eb3', filename='extra_32x32.mat'). Got: UrlInfo(size=356.32 MiB, checksum='f006a3c7ed7937c396de4201a543351a64a8fe03109691d2ed01c2f881d1c943', filename='extra_32x32.mat').To debug, see: https://www.tensorflow.org/datasets/overview#fixing_nonmatchingchecksumerror",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonMatchingChecksumError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d59addc2d76f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m svhn_test, info = tfds.load(\"svhn_cropped\", split=\"test\", \n\u001b[0m\u001b[1;32m      2\u001b[0m                       as_supervised=True, with_info=True)\n\u001b[1;32m      3\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total examples in the test set of SVHN: {tf.data.experimental.cardinality(svhn_test).numpy()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    442\u001b[0m           \u001b[0;31m# Old version of TF are not os.PathLike compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmock_gfile_pathlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             self._download_and_prepare(\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0moptional_pipeline_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m       split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n\u001b[0m\u001b[1;32m   1148\u001b[0m           \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptional_pipeline_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       )\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/image_classification/svhn.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     output_files = dl_manager.download({\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_32x32.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_32x32.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;31m# Add progress bar to follow the download state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   def iter_archive(\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Wait promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/promise/promise.py\u001b[0m in \u001b[0;36m_target_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# type: (bool) -> Any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/promise/promise.py\u001b[0m in \u001b[0;36m_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mraise_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mtry_catch\u001b[0;34m(handler, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(dl_result)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;31m# Post-process the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     return future.then(lambda dl_result: self._register_or_validate_checksums(  # pylint: disable=g-long-lambda\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_register_or_validate_checksums\u001b[0;34m(self, path, url, expected_url_info, computed_url_info, checksum_path, url_path)\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0;31m#   download). This is expected as it might mean the downloaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;31m#   was corrupted. Note: The tmp file isn't deleted to allow inspection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       _validate_checksums(\n\u001b[0m\u001b[1;32m    417\u001b[0m           \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m           \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gODIN/lib/python3.9/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_validate_checksums\u001b[0;34m(url, path, computed_url_info, expected_url_info, force_checksums_validation)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m'https://www.tensorflow.org/datasets/overview#fixing_nonmatchingchecksumerror'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     )\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNonMatchingChecksumError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNonMatchingChecksumError\u001b[0m: Artifact http://ufldl.stanford.edu/housenumbers/extra_32x32.mat, downloaded to /home/dolgenercantu/tensorflow_datasets/downloads/ufldl.stanford.edu_housenumber_extra_32x322H3BskdvSy0nozmNN-lLEutTDhyQSJDShKe3tccJQqI.mat.tmp.0199864c86d74b5d9e8e0157df6fe89b/extra_32x32.mat, has wrong checksum. Expected: UrlInfo(size=1.24 GiB, checksum='a133a4beb38a00fcdda90c9489e0c04f900b660ce8a316a5e854838379a71eb3', filename='extra_32x32.mat'). Got: UrlInfo(size=356.32 MiB, checksum='f006a3c7ed7937c396de4201a543351a64a8fe03109691d2ed01c2f881d1c943', filename='extra_32x32.mat').To debug, see: https://www.tensorflow.org/datasets/overview#fixing_nonmatchingchecksumerror"
     ]
    }
   ],
   "source": [
    "svhn_test, info = tfds.load(\"svhn_cropped\", split=\"test\", \n",
    "                      as_supervised=True, with_info=True)\n",
    "tfds.show_examples(svhn_test, info)\n",
    "print(f\"Total examples in the test set of SVHN: {tf.data.experimental.cardinality(svhn_test).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiEoAkopowcY"
   },
   "source": [
    "## Prepare the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tzvQDiJSf8Z"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "AUTO = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njjGGYBwQE8d"
   },
   "outputs": [],
   "source": [
    "# SVHN test set\n",
    "svhn_test = (svhn_test\n",
    "             .map(lambda x, y: (tf.cast(x, tf.float32), y), \n",
    "                  num_parallel_calls=AUTO))\n",
    "\n",
    "# CIFAR10 test set\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_test = x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7R7TjV1XSmJ9"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "cifar10_test = ds.skip(1000).take(len(x_test) - 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfEaWU0xSmJ-",
    "outputId": "51640be6-f9d0-445b-81e2-bb87bce3d757"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svhn': 26032, 'cifar10_test': 9000}"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_SAMPLE_MAPPING = {\n",
    "    \"svhn\": tf.data.experimental.cardinality(svhn_test).numpy(),\n",
    "    \"cifar10_test\": tf.data.experimental.cardinality(cifar10_test).numpy()\n",
    "}\n",
    "NUM_SAMPLE_MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv-nA5hkSmJ-"
   },
   "source": [
    "We are skipping 1000 samples because we used them to calculate the perturbation magnitude (refer to [this notebook](https://git.io/JOTgx)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZttgyK6o1U5"
   },
   "source": [
    "## Define our `scorer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzUie-5-8jAZ"
   },
   "outputs": [],
   "source": [
    "# Let's define our model to obtain scores.\n",
    "scorer = tf.keras.Model(rn_odin_model.input, rn_odin_model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtilNHIPo6WX"
   },
   "source": [
    "## Perturbing utility\n",
    "\n",
    "As per equation 9 of the paper, we will be perturbing the input images with $\\epsilon$ which was calculated in [this notebook](https://git.io/JOTgx). The value we derived is **0.04**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1u32-NbTHx1"
   },
   "outputs": [],
   "source": [
    "def perturb_images(images, model, epsilon=0.04):\n",
    "\n",
    "    test_ds_var = tf.Variable(images, trainable=True)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Calculate the scores.\n",
    "        tape.watch(test_ds_var)\n",
    "        logits = model(test_ds_var, training=False)\n",
    "        loss = tf.reduce_max(logits, axis=1)\n",
    "        loss = -tf.reduce_mean(loss)\n",
    "\n",
    "    # Calculate the gradients of the scores with respect to the inputs.\n",
    "    gradients = tape.gradient(loss, test_ds_var)\n",
    "    gradients = tf.math.greater_equal(gradients, 0)\n",
    "    gradients = tf.cast(gradients, tf.float32)\n",
    "    gradients = (gradients - 0.5) * 2\n",
    "\n",
    "    # Perturb the inputs and derive new mean score.\n",
    "    # test_ds_var.assign_add(epsilon * gradients)\n",
    "    static_tensor = tf.convert_to_tensor(test_ds_var)\n",
    "    static_tensor = static_tensor - epsilon * gradients\n",
    "    static_tensor = tf.clip_by_value(static_tensor, 0., 255.)\n",
    "    \n",
    "    return static_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua1UDZojp8PU"
   },
   "source": [
    "## Model evalution with AUROC & TNR@TPR95\n",
    "\n",
    "The authors use two metrics for evaluation -- **AUROC** & **TNR@TPR95**. \n",
    "\n",
    "Here are the steps we will roughly be following:\n",
    "\n",
    "1. Perturb the images using `perturb_images()`. For this, we will be using `scorer`. \n",
    "2. Pass those images to `model` to obtain predictions. From the paper - \"At testing time, the class prediction can be made by either calculating $\\arg \\max _{i} f_{i}(\\boldsymbol{x})$ or\n",
    "$\\arg \\max _{i} h_{i}(\\boldsymbol{x})$ (both will give the same predictions).\"\n",
    "3. Use the original labels of the dataset under evaluation and the prediction scores from (2) and calculate the metrics. \n",
    "\n",
    "For evaluating the baseline model, we won't be adding perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi3fwtsJSmJ_"
   },
   "outputs": [],
   "source": [
    "# We first perturb the images from both of the datasets.\n",
    "\n",
    "def create_pertubed_ds(ds, model, ds_name):\n",
    "    num_samples = NUM_SAMPLE_MAPPING[ds_name]\n",
    "    perturbed_images = np.zeros((num_samples, 32, 32, 3))\n",
    "    unchanged_labels = np.zeros((num_samples, ))\n",
    "    \n",
    "    for i, (image, label) in enumerate(tqdm(ds)):\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        perturbed_images[i] = perturb_images(image, model)\n",
    "        unchanged_labels[i] = label\n",
    "    \n",
    "    perturbed_ds = tf.data.Dataset.from_tensor_slices((perturbed_images, unchanged_labels))\n",
    "    return perturbed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "27ebbdc62de84d708fa25185b19b479b",
      "d0578b19efd143959e95d922ab194d08"
     ]
    },
    "id": "BK03CmlHSmJ_",
    "outputId": "9478ef8a-1cf0-4b1c-a96e-70547d9bf5ca"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ebbdc62de84d708fa25185b19b479b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0578b19efd143959e95d922ab194d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perturbed_svhn = create_pertubed_ds(svhn_test, scorer, \"svhn\")\n",
    "pertubed_cifar10 = create_pertubed_ds(cifar10_test, scorer, \"cifar10_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mVBhOgBSmKA"
   },
   "outputs": [],
   "source": [
    "# We create new data loaders.\n",
    "perturbed_svhn = perturbed_svhn.batch(BATCH_SIZE)\n",
    "pertubed_cifar10 = pertubed_cifar10.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLzU6GMqSmKA",
    "outputId": "4fff73ec-dc09-4ae6-f274-b178726c2d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generalized_odin': {'TNR': 0.5418715427166565, 'AUROC': 0.9215311326230964}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUROC.\n",
    "print(metrics.metric(pertubed_cifar10, perturbed_svhn, rn_odin_model, stype=\"generalized_odin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvxQGujtSmKA",
    "outputId": "91632ebe-02ce-4aa4-82be-7552ef699202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': {'TNR': 0.4053088506453596, 'AUROC': 0.9114120185412826}}\n"
     ]
    }
   ],
   "source": [
    "# Baseline AUROC (with perturbation).\n",
    "cifar10_test = pertubed_cifar10.batch(BATCH_SIZE)\n",
    "print(metrics.metric(pertubed_cifar10, perturbed_svhn, rn_baseline_model, stype=\"baseline\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Evaluation_OOD.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
